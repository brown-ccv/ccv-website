---
title: AI Services
description: "Access to large language models and AI tools through CCV's computing infrastructure."
---

<SectionHeader
  title="Overview"
/>

CCV provides access to cutting-edge AI tools and large language models through our high-performance computing infrastructure. Whether you need to run LLMs for research, explore AI capabilities, or integrate AI into your computational workflows, we have the resources and expertise to support your needs.

<MDXButton href="https://docs.ccv.brown.edu/ai-tools/privacy-statement">
  CCV AI Tools Privacy Statement
</MDXButton>

<SectionHeader
  title="Ollama - Large Language Models"
/>

Ollama is a framework that allows you to run large language models directly on Oscar's GPU nodes. CCV hosts dozens of open-weight LLMs including Llama 3.3, DeepSeek-r1, Mistral, and Gemma3.

<MDXButton href="https://docs.ccv.brown.edu/oscar/large-language-models/ollama">
  View Documentation
</MDXButton>

## Getting Started

### 1. Set Up Environment
First, connect to Oscar and set the environment variable for CCV-hosted models:

```bash
echo 'export OLLAMA_MODELS=/oscar/data/shared/ollama_models' >> ~/.bashrc
source ~/.bashrc
```

### 2. Request GPU Resources
Request a GPU node with appropriate resources:

```bash
interact -n 4 -m 32g -q gpu -g 1 -t 1:00:00
```

### 3. Start Ollama Server
Load the Ollama module and start the server:

```bash
module load ollama
ollama serve
```

### 4. Run Models Interactively
In a new terminal session, connect to your GPU node and start chatting:

```bash
ssh gpuXXXX  # Replace with your node number
module load ollama
ollama run llama3.2
```

## Available Models

CCV hosts a comprehensive collection of models including:

- **Llama Models**: llama3.1, llama3.2, llama3.3 (various sizes)
- **Code Models**: codellama, deepseek-coder-v2, starcoder2
- **General Purpose**: mistral, gemma2, phi3, qwen2.5
- **Specialized**: llava (vision), moondream (vision)

For the complete list, run `ollama list` after starting your server.

## Python Integration

You can also use Ollama models programmatically with Python:

```python
import ollama

response = ollama.chat(model='llama3.2', messages=[
    {
        'role': 'user',
        'content': 'Write a function to compute Fibonacci numbers in Rust.',
    },
])

print(response['message']['content'])
```

## Performance Notes

- LLMs perform best on GPUs due to their parallel architecture
- Large models (like llama3.1:405b) may require multiple GPUs
- Request additional resources for optimal performance
- Models are automatically distributed across available GPUs


<SectionHeader
  title="ChatCCV"
/>

A conversational AI assistant for CCV services and support.

<MDXButton href="https://ai.ccv.brown.edu/">
  Try ChatCCV
</MDXButton>

## Transcribe

Transcribe audio files to text using Google Gemini, OpenAI Whisper, or Azure AI Speech STT.

<MDXButton href="https://docs.ccv.brown.edu/ai-tools/transcribe">
  View Documentation
</MDXButton>

## LibreChat

LibreChat is an easy-to-use, open-source chat platform that lets you talk to AI in a private, customizable way. It's free to use and gives you full control over your data.

<MDXButton href="https://docs.ccv.brown.edu/ai-tools/services/librechat">
  View Documentation
</MDXButton>

## Ask Oscar

Ask Oscar is an AI assistant that specializes in answering questions about CCV and its services using retrieval augmented generation (RAG). Currently, it answers questions about Oscar, Brown University's HPC cluster. It has access to Oscar's documentation and can help you find the information you need. Support for other CCV services will arrive soon.

<MDXButton href="https://docs.ccv.brown.edu/ai-tools/services/ask-oscar">
  View Documentation
</MDXButton>

Ask Oscar is powered by the latest version of the OpenAI GPT-4o model served by Azure OpenAI. Different from models served directly by OpenAI, information provided to the model will not be used by OpenAI or Microsoft for training purposes. Please check the Data, privacy, and security for Azure OpenAI for more information. Nevertheless, please avoid sharing sensitive information with the model.

<MDXButton href="https://platform.openai.com/docs/models">
  OpenAI Models
</MDXButton>

<MDXButton href="https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/data-privacy?tabs=azure-portal">
  Azure OpenAI Data Privacy
</MDXButton>

**Note**: Ask Oscar is currently under development as a proof of concept. The information about the Oscar documentation is not up-to-date and may be incorrect.


<SectionHeader
  title="Climate and Development Lab"
/>
**Coming soon in Project Carousel**

![Climate Development Lab](/images/services/climate-development-lab.png)

Parse Facebook posts using nuanced prompts/instructions and separately parsing text and images to avoid potentially biasing the LLM. Refactor original code into production (modularization, optimization, reusability, and documentation).

<MDXButton href="https://www.climatedevlab.brown.edu/">
  Lab Website
</MDXButton>